{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14003937,"sourceType":"datasetVersion","datasetId":8922616},{"sourceId":14138116,"sourceType":"datasetVersion","datasetId":9009524},{"sourceId":14140743,"sourceType":"datasetVersion","datasetId":9011557},{"sourceId":14207345,"sourceType":"datasetVersion","datasetId":9061731}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# YOLOOO","metadata":{}},{"cell_type":"code","source":"import os\nimport yaml\n\n# --- PARAMETER KONFIGURASI YAML ---\n# Jumlah kelas objek (HANYA kelas objek, tidak termasuk background)\nNUM_CLASSES = 1\n\n# Daftar nama kelas Anda\nclass_names = ['sakit']\n\n# Path ke direktori data yang sudah Anda buat di /kaggle/working/\nYOLO_DATA_PATH = \"/kaggle/input/data-augmented-citra-jagung/YOLOtraining/Split_aug\"\n\n# Nama file konfigurasi\nYAML_FILE_NAME = \"data2.yaml\"\n\n# 1. Definisikan isi file YAML\ndata_yaml_content = {\n    'path': YOLO_DATA_PATH,\n    'train': 'train/images',  # Path relatif dari YOLO_DATA_PATH\n    'val': 'val/images',      # Path relatif dari YOLO_DATA_PATH\n    'test': 'test/images',    # Path relatif dari YOLO_DATA_PATH\n    'nc': NUM_CLASSES,        # Jumlah kelas\n    'names': class_names      # Nama-nama kelas\n}\n\n# 2. Tulis data ke file YAML di working directory\nwith open(os.path.join(\"/kaggle/working/\", YAML_FILE_NAME), 'w') as f:\n    yaml.dump(data_yaml_content, f, default_flow_style=False)\n\nprint(f\"File konfigurasi {YAML_FILE_NAME} berhasil dibuat\")\nprint(data_yaml_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T06:28:56.635950Z","iopub.execute_input":"2025-12-18T06:28:56.636693Z","iopub.status.idle":"2025-12-18T06:28:56.660507Z","shell.execute_reply.started":"2025-12-18T06:28:56.636667Z","shell.execute_reply":"2025-12-18T06:28:56.659922Z"}},"outputs":[{"name":"stdout","text":"File konfigurasi data2.yaml berhasil dibuat\n{'path': '/kaggle/input/data-augmented-citra-jagung/YOLOtraining/Split_aug', 'train': 'train/images', 'val': 'val/images', 'test': 'test/images', 'nc': 1, 'names': ['sakit']}\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Traing Model YOLO, beberapa cell berisikan hyperparameter yang berbeda-beda. Lokasi penyimpanan hasil dapat disesuaikan kembali.","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom ultralytics import YOLO\nimport datetime # Import untuk unique sheet names\n\n# --- KONFIGURASI PATH DAN HYPERPARAMETER ---\n\n# Path ke file data.yaml Anda\nDATA_YAML_PATH = \"/kaggle/working/data2.yaml\"\n\n# Ganti dengan hyperparameter terbaik hasil tuning manual Anda (atau gunakan default)\nBEST_LR = 0.01      # Learning Rate awal (Default)\nBEST_MOMENTUM = 0.937 # Momentum (Default)\nFINAL_EPOCHS = 20   # Jumlah epoch untuk pelatihan final (Ganti sesuai kebutuhan)\nBATCH_SIZE = 32        # Ukuran batch (Sesuaikan dengan VRAM GPU Kaggle)\n\n# Output directory di Google Drive untuk semua eksperimen YOLO\n# Ini akan membuat folder seperti: /content/drive/MyDrive/EAS VISIKOM/YOLO_Output/yolo_production/YOLOv8_Final_Training_Model2\nOUTPUT_BASE_DRIVE_DIR = \"/kaggle/working/Hasil\"\n\n# Nama proyek (subfolder di OUTPUT_BASE_DRIVE_DIR)\nPROJECT_NAME = \"yolo_production\"\n\n# Nama eksperimen final (output akan disimpan di PROJECT_NAME/EXPERIMENT_NAME)\nEXPERIMENT_NAME = 'YOLOv8_Final_Training_Model1'\n\n# --- INIALISASI MODEL ---\n# Muat model pre-trained (yolov8n.pt)\nmodel = YOLO('yolov8n.pt')\n\n# ----------------------------------------------------\n# Bagian 1: Pelatihan Final\n# ----------------------------------------------------\nprint(\"---> Memulai Pelatihan Final YOLOv8 --->\")\n\n\nTRAINING_ARGS = {\n    'data': DATA_YAML_PATH,\n    'epochs': FINAL_EPOCHS,\n    'imgsz': 640,\n    'batch': BATCH_SIZE,\n    'name': EXPERIMENT_NAME, # Experiment name within the project\n    'project': os.path.join(OUTPUT_BASE_DRIVE_DIR, PROJECT_NAME), # Full path to the project folder on Drive\n    'lr0': BEST_LR,\n    'momentum': BEST_MOMENTUM,\n    'val': True, # Wajib untuk mendapatkan metrik validasi\n    'plots': True # Menghasilkan plot loss dan metrik\n}\n\n# Mulai Pelatihan\nresults = model.train(\n    **TRAINING_ARGS\n)\n\nprint(\"\\n‚úÖ Pelatihan Selesai!\")\n\n# ----------------------------------------------------\n# Bagian 2: Evaluasi dan Pencatatan Loss\n# ----------------------------------------------------\n\n# Tentukan path tempat hasil disimpan (otomatis dibuat oleh Ultralytics)\n# Ultralytics menyimpan hasil relatif terhadap direktori kerja saat ini,\n# biasanya di `runs/detect/project_name/experiment_name`.\n# Objek `results` secara langsung menyediakan direktori penyimpanan.\nOUTPUT_BASE_DIR = str(results.save_dir) # This will now be the Drive path\nBEST_MODEL_PATH = os.path.join(OUTPUT_BASE_DIR, 'weights', 'best.pt')\nRESULTS_CSV_PATH = os.path.join(OUTPUT_BASE_DIR, 'results.csv')\n\n# Path untuk menyimpan hasil ke file Excel\n# The Excel report should also go into the new OUTPUT_BASE_DIR\nEXCEL_OUTPUT_DIR = os.path.join(OUTPUT_BASE_DIR, 'Excel_Reports') # Changed this line\nos.makedirs(EXCEL_OUTPUT_DIR, exist_ok=True)\nEXCEL_REPORT_PATH = os.path.join(EXCEL_OUTPUT_DIR, f'{PROJECT_NAME}_{EXPERIMENT_NAME}_training_results.xlsx') # Added experiment name to differentiate reports\n\nprint(\"\\n--- Ringkasan Hasil Pelatihan ---\")\n\n# A. Mengambil Metrik mAP (Mean Average Precision)\ntry:\n    # Akses metrik langsung dari objek results.metrics (DetMetrics object)\n    map50 = results.metrics.box.map50\n    map50_95 = results.metrics.box.map\n\n    print(f\"Metrik Deteksi (Bounding Box - B):\")\n    print(f\"  mAP50 (Akurasi di IoU 50%): {map50:.4f}\")\n    print(f\"  mAP50-95 (Akurasi Rata-rata): {map50_95:.4f}\")\n\nexcept Exception as e:\n    print(f\"Terjadi error saat mencoba mengakses mAP dari results.metrics: {e}. Mencoba membaca dari CSV...\")\n    # Fallback to reading from CSV if direct access fails or for consistency\n    try:\n        df_results_full = pd.read_csv(RESULTS_CSV_PATH)\n        last_row_full = df_results_full.iloc[-1]\n        map50 = last_row_full['metrics/mAP50(B)']\n        map50_95 = last_row_full['metrics/mAP50-95(B)']\n        print(f\"Metrik Deteksi (Bounding Box - B) dari CSV:\")\n        print(f\"  mAP50 (Akurasi di IoU 50%): {map50:.4f}\")\n        print(f\"  mAP50-95 (Akurasi Rata-rata): {map50_95:.4f}\")\n    except Exception as csv_e:\n        print(f\"‚ùå ERROR membaca mAP dari CSV: {csv_e}\")\n\n# B. Mengambil Nilai Loss dari File results.csv dan menyimpannya ke Excel\ntry:\n    # Membaca file results.csv yang dibuat oleh Ultralytics\n    df_results = pd.read_csv(RESULTS_CSV_PATH)\n\n    # Mencari baris terakhir (epoch terakhir)\n    last_row = df_results.iloc[-1]\n\n    # Kolom Loss di Ultralytics:\n    # box_loss: Loss untuk bounding box localization\n    # cls_loss: Loss untuk classification\n    # dfl_loss: Loss untuk Distribution Focal Loss (digunakan di YOLOv8)\n\n    train_box_loss = last_row['train/box_loss']\n    train_cls_loss = last_row['train/cls_loss']\n    val_box_loss = last_row['val/box_loss']\n    val_cls_loss = last_row['val/cls_loss']\n\n    print(\"\\nNilai Loss di Akhir Pelatihan:\")\n    print(f\"  Total Train Loss (Box+Cls): {(train_box_loss + train_cls_loss):.4f}\")\n    print(f\"  Total Validasi Loss (Box+Cls): {(val_box_loss + val_cls_loss):.4f}\")\n    print(f\"  (Detail: Train Box Loss: {train_box_loss:.4f} | Val Box Loss: {val_box_loss:.4f})\")\n\n    # --- Menyimpan ke Excel/Spreadsheet --- #\n    # Buat nama sheet yang unik berdasarkan waktu\n    timestamp_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n    sheet_name = f\"Run_{timestamp_str}\"\n\n    # Gunakan pd.ExcelWriter untuk menulis ke file Excel.\n    # 'mode='a'' untuk append jika file sudah ada.\n    # 'if_sheet_exists='new'' akan membuat sheet baru jika nama sheet sudah ada (atau file belum ada).\n    # 'engine='openpyxl'' diperlukan untuk mode append dan .xlsx.\n    with pd.ExcelWriter(EXCEL_REPORT_PATH, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n        df_results.to_excel(writer, sheet_name=sheet_name, index=False)\n\n    print(f\"‚úÖ Hasil pelatihan disimpan ke sheet '{sheet_name}' di file Excel: {EXCEL_REPORT_PATH}\")\n\n\nexcept FileNotFoundError:\n    print(f\"\\n‚ùå ERROR: File results.csv tidak ditemukan di {RESULTS_CSV_PATH}.\")\n    print(\"Pastikan eksperimen berjalan sepenuhnya dan tidak ada error file system.\")\nexcept Exception as e:\n    print(f\"\\n‚ùå ERROR membaca Loss dari CSV atau menulis ke Excel: {e}\")\n\n# ----------------------------------------------------\n# Bagian 3: Konfirmasi Penyimpanan Model\n# ----------------------------------------------------\nprint(\"\\n--- Konfirmasi Penyimpanan Model ---\")\nprint(f\"Model terbaik tersimpan secara otomatis di:\")\nprint(f\"üíæ {BEST_MODEL_PATH}\")\nprint(f\"Log pelatihan (loss dan metrik) tersimpan di:\")\nprint(f\"üìÑ {RESULTS_CSV_PATH}\")\nprint(f\"Laporan Excel tersimpan di:\")\nprint(f\"üìä {EXCEL_REPORT_PATH}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom ultralytics import YOLO\nimport datetime\n\n# --- KONFIGURASI PATH DAN HYPERPARAMETER ---\n\n# Path ke file data.yaml Anda\nDATA_YAML_PATH = \"/kaggle/working/data2.yaml\"\n\n# Hyperparameter\nBEST_LR = 0.01      \nBEST_MOMENTUM = 0.937 \nFINAL_EPOCHS = 100   \nBATCH_SIZE = 16       \n\n# Output directory (Di Kaggle Output)\nOUTPUT_BASE_DRIVE_DIR = \"/kaggle/working/Hasil\"\nPROJECT_NAME = \"yolo_production\"\nEXPERIMENT_NAME = 'YOLOv8_Final_Training_Model_final'\n\n# --- INIALISASI MODEL ---\nmodel = YOLO('yolov8n.pt')\n\n# ----------------------------------------------------\n# Bagian 1: Pelatihan Final\n# ----------------------------------------------------\nprint(\"---> Memulai Pelatihan Final YOLOv8 --->\")\n\nTRAINING_ARGS = {\n    'data': DATA_YAML_PATH,\n    'epochs': FINAL_EPOCHS,\n    'imgsz': 640,\n    'batch': BATCH_SIZE,\n    'name': EXPERIMENT_NAME, \n    'project': os.path.join(OUTPUT_BASE_DRIVE_DIR, PROJECT_NAME), \n    'lr0': BEST_LR,\n    'momentum': BEST_MOMENTUM,\n    'val': True, \n    'plots': True \n}\n\n# Mulai Pelatihan\nresults = model.train(**TRAINING_ARGS)\n\nprint(\"\\n‚úÖ Pelatihan Selesai!\")\n\n# ----------------------------------------------------\n# Bagian 2: Evaluasi dan Pencatatan Loss\n# ----------------------------------------------------\n\n# Konversi path ke string agar aman\nOUTPUT_BASE_DIR = str(results.save_dir) \nBEST_MODEL_PATH = os.path.join(OUTPUT_BASE_DIR, 'weights', 'best.pt')\nRESULTS_CSV_PATH = os.path.join(OUTPUT_BASE_DIR, 'results.csv')\n\n# Setup Folder Excel\nEXCEL_OUTPUT_DIR = os.path.join(OUTPUT_BASE_DIR, 'Excel_Reports') \nos.makedirs(EXCEL_OUTPUT_DIR, exist_ok=True)\nEXCEL_REPORT_PATH = os.path.join(EXCEL_OUTPUT_DIR, f'{PROJECT_NAME}_{EXPERIMENT_NAME}_training_results.xlsx') \n\nprint(\"\\n--- Ringkasan Hasil Pelatihan ---\")\n\n# A. Mengambil Metrik mAP\n# Menggunakan logic fallback yang Anda buat (sudah bagus)\ntry:\n    map50 = results.box.map50 # Update syntax terbaru Ultralytics biasanya results.box.map50\n    map50_95 = results.box.map\n    print(f\"Metrik Deteksi (Bounding Box - B):\")\n    print(f\"  mAP50 : {map50:.4f}\")\n    print(f\"  mAP50-95 : {map50_95:.4f}\")\nexcept:\n    try:\n        # Fallback ke metrics object lama atau CSV\n        map50 = results.metrics.box.map50\n        map50_95 = results.metrics.box.map\n        print(f\"Metrik Deteksi (Bounding Box - B) [via metrics object]:\")\n        print(f\"  mAP50 : {map50:.4f}\")\n        print(f\"  mAP50-95 : {map50_95:.4f}\")\n    except Exception as e:\n        print(f\"Gagal akses langsung metrik object, membaca dari CSV... ({e})\")\n        try:\n            df_results_full = pd.read_csv(RESULTS_CSV_PATH)\n            # Menghapus spasi di nama kolom agar aman\n            df_results_full.columns = df_results_full.columns.str.strip()\n            last_row_full = df_results_full.iloc[-1]\n            map50 = last_row_full['metrics/mAP50(B)']\n            map50_95 = last_row_full['metrics/mAP50-95(B)']\n            print(f\"Metrik Deteksi dari CSV: mAP50={map50:.4f}, mAP50-95={map50_95:.4f}\")\n        except Exception as csv_e:\n            print(f\"‚ùå ERROR membaca mAP dari CSV: {csv_e}\")\n\n# B. Simpan ke Excel (BAGIAN YANG DIPERBAIKI)\ntry:\n    df_results = pd.read_csv(RESULTS_CSV_PATH)\n    \n    # Bersihkan nama kolom (kadang ada spasi ekstra di CSV output YOLO)\n    df_results.columns = df_results.columns.str.strip()\n\n    timestamp_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n    sheet_name = f\"Run_{timestamp_str}\"\n\n    print(f\"Menyimpan ke Excel: {EXCEL_REPORT_PATH}\")\n\n    # LOGIKA PERBAIKAN: Cek apakah file sudah ada atau belum\n    if os.path.exists(EXCEL_REPORT_PATH):\n        # Jika file ADA, gunakan mode 'a' (append) dan if_sheet_exists='new'\n        with pd.ExcelWriter(EXCEL_REPORT_PATH, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n            df_results.to_excel(writer, sheet_name=sheet_name, index=False)\n        print(\"Mode: APPEND (File sudah ada)\")\n    else:\n        # Jika file TIDAK ADA, gunakan mode 'w' (write)\n        # PENTING: Jangan gunakan parameter 'if_sheet_exists' di mode 'w'\n        with pd.ExcelWriter(EXCEL_REPORT_PATH, engine='openpyxl', mode='w') as writer:\n            df_results.to_excel(writer, sheet_name=sheet_name, index=False)\n        print(\"Mode: WRITE (File baru dibuat)\")\n\n    print(f\"‚úÖ Hasil pelatihan berhasil disimpan ke sheet '{sheet_name}'\")\n\nexcept Exception as e:\n    print(f\"\\n‚ùå ERROR Manajemen Excel: {e}\")\n\n# ----------------------------------------------------\n# Bagian 3: Konfirmasi\n# ----------------------------------------------------\nprint(\"\\n--- Selesai ---\")\nprint(f\"Model: {BEST_MODEL_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T06:31:55.909523Z","iopub.execute_input":"2025-12-18T06:31:55.910060Z","iopub.status.idle":"2025-12-18T07:11:39.161290Z","shell.execute_reply.started":"2025-12-18T06:31:55.910026Z","shell.execute_reply":"2025-12-18T07:11:39.160458Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 65.4MB/s 0.1s\n---> Memulai Pelatihan Final YOLOv8 --->\nUltralytics 8.3.240 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/data2.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=YOLOv8_Final_Training_Model_final, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/Hasil/yolo_production, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 16.4MB/s 0.0s\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 69.7MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 17.3¬±2.4 MB/s, size: 2447.1 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/data-augmented-citra-jagung/YOLOtraining/Split_aug/train/labels... 227 images, 98 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 325/325 70.6it/s 4.6s0.0s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mtrain: \u001b[0mCache directory /kaggle/input/data-augmented-citra-jagung/YOLOtraining/Split_aug/train is not writable, cache not saved.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 38.4¬±11.0 MB/s, size: 3889.9 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/data-augmented-citra-jagung/YOLOtraining/Split_aug/val/labels... 346 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 346/346 84.9it/s 4.1s0.1s\nWARNING ‚ö†Ô∏è \u001b[34m\u001b[1mval: \u001b[0mCache directory /kaggle/input/data-augmented-citra-jagung/YOLOtraining/Split_aug/val is not writable, cache not saved.\nPlotting labels to /kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final/labels.jpg... \n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\nCorrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      1/100      2.15G      2.217       3.25      1.866         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.2it/s 17.3s0.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 27% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/11 1.5it/s 2.5s<5.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.6it/s 9.9s<0.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2s/it 13.4s\n                   all        346       2909      0.019      0.679     0.0375     0.0174\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      2/100       2.8G      1.929      2.348      1.497         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.5s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.8s0.7s\n                   all        346       2909     0.0177      0.633      0.114     0.0479\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      3/100       2.8G      1.837      2.339      1.478        129        640: 62% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/21 2.6it/s 6.3s<3.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      3/100      2.83G       1.84      2.285      1.464         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.5it/s 5.8s<1.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.5s.4s\n                   all        346       2909      0.357     0.0708     0.0931     0.0395\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      4/100      2.85G      1.872       2.18       1.49         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 13.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.6it/s 7.9s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.4s\n                   all        346       2909      0.214      0.239      0.143     0.0612\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      5/100      2.85G      1.864      2.093      1.506         99        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 1.8it/s 10.4s<2.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      5/100      2.85G      1.845      2.061      1.493         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.9s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.5it/s 8.7s<0.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 11.0s\n                   all        346       2909      0.257       0.25       0.14     0.0545\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      6/100      2.88G      1.854      1.969      1.504         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.8s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.5s0.8s\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"                   all        346       2909      0.123      0.159     0.0586     0.0229\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      7/100      2.88G      1.887      2.008      1.511        124        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 3.1it/s 3.9s<3.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      7/100       2.9G      1.818       1.98      1.492         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.1s1.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 82% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 9/11 1.9it/s 9.3s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.8s.4s\n                   all        346       2909      0.222      0.181      0.113     0.0446\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      8/100       2.9G      1.792        1.9      1.478        103        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 4.3it/s 4.4s<2.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      8/100      2.91G      1.848      1.948      1.482         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.9s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.4s0.6s\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"                   all        346       2909      0.403      0.171       0.15     0.0572\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      9/100      2.91G      1.857       1.87      1.502         75        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 2.2it/s 4.8s<4.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      9/100      2.92G       1.81      1.833      1.482         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.9it/s 4.7s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.8s.4s\n                   all        346       2909        0.4      0.207      0.182      0.081\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     10/100      2.95G      1.776      1.766      1.468         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.4s1.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 64% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 7/11 3.3it/s 1.9s<1.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.3s0.5s\n                   all        346       2909      0.359      0.204      0.159     0.0683\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     11/100      2.96G      1.777       1.78      1.459         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 14.1s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.9it/s 4.5s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.8s.3s\n                   all        346       2909       0.33      0.259      0.199     0.0782\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     12/100      2.96G      1.787      1.816      1.435         88        640: 57% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 12/21 2.0it/s 5.0s<4.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     12/100      2.98G      1.779      1.775      1.423         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.9s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.7s0.5s\n                   all        346       2909      0.397      0.264      0.232      0.101\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     13/100      2.98G      1.769      1.771      1.434        138        640: 33% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 7/21 5.2it/s 1.3s<2.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     13/100      2.99G      1.749      1.727       1.43         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.2s0.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.9it/s 6.7s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 12.0s.4s\n                   all        346       2909      0.474      0.277       0.26      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     14/100      2.99G      1.729      1.647      1.416         97        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 2.3it/s 11.0s<1.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     14/100      2.99G      1.714      1.632      1.411         82        640: 86% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 18/21 3.0it/s 11.2s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     14/100      3.02G      1.695      1.617      1.408         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.4it/s 8.1s0.5s\n                   all        346       2909      0.436      0.349      0.314      0.133\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     15/100      3.03G      1.728      1.595      1.407         52        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.2s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.2it/s 4.9s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.5s.3s\n                   all        346       2909      0.464      0.319      0.292      0.113\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     16/100      3.03G      1.787      1.656      1.452         94        640: 76% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ 16/21 2.7it/s 8.8s<1.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     16/100      3.05G      1.767      1.647       1.44         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.1s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.6s0.6s\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"                   all        346       2909      0.476      0.353      0.341      0.139\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     17/100      3.05G      1.789      1.641      1.413         86        640: 33% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 7/21 5.1it/s 1.5s<2.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     17/100      3.06G      1.754       1.64       1.41         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.9it/s 5.3s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.1s.4s\n                   all        346       2909      0.457      0.387      0.371      0.155\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     18/100      3.08G      1.687      1.634      1.402         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.6s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.0s0.5s\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"                   all        346       2909      0.486       0.36      0.365      0.155\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     19/100      3.08G      1.709      1.599       1.43         92        640: 71% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 15/21 3.6it/s 8.3s<1.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     19/100       3.1G      1.718      1.578      1.427         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.6it/s 5.7s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.2s.3s\n                   all        346       2909      0.429      0.282      0.261      0.113\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     20/100      3.12G      1.671      1.526      1.391         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 12.0s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.2s0.5s\n                   all        346       2909      0.482      0.291      0.289      0.129\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     21/100      3.12G      1.671      1.479      1.383         92        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 2.4it/s 10.4s<1.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     21/100      3.12G      1.682      1.476      1.389         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.2it/s 5.4s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.2s.3s\n                   all        346       2909      0.501      0.345       0.35      0.151\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     22/100      3.12G       1.68      1.505      1.362        149        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 3.8it/s 4.4s<2.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     22/100      3.15G      1.672      1.508       1.35         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.8s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.6s0.6s\n                   all        346       2909      0.534      0.269      0.284      0.121\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     23/100      3.15G       1.74      1.569      1.392        103        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/21 4.6it/s 2.2s<2.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     23/100      3.17G       1.72      1.523      1.405         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.6s0.3s\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 82% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 9/11 1.7it/s 8.8s<1.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.2s.4s\n                   all        346       2909      0.419      0.312      0.302      0.134\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     24/100      3.19G       1.68      1.511      1.404         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 13.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 64% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 7/11 3.0it/s 2.3s<1.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.3s0.7s\n                   all        346       2909      0.519      0.325      0.335      0.136\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     25/100      3.19G      1.649      1.435      1.379         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.6s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 36% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4/11 2.8it/s 1.1s<2.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.0it/s 6.3s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.8s.3s\n                   all        346       2909      0.444      0.316      0.304      0.127\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     26/100      3.22G      1.665      1.454      1.375         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.2s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.3s0.5s\n                   all        346       2909      0.457      0.343      0.345      0.144\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     27/100      3.22G      1.643      1.444      1.348         76        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/21 3.7it/s 2.4s<3.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     27/100      3.24G      1.632      1.435      1.352         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.8s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.3it/s 5.6s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.5s.3s\n                   all        346       2909      0.476      0.352      0.344      0.151\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     28/100      3.24G      1.669      1.255      1.382        110        640: 0% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0/21  0.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     28/100      3.26G      1.628      1.418       1.35         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.9s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.3s0.7s\n                   all        346       2909       0.54      0.317      0.342      0.139\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     29/100      3.26G       1.68      1.411      1.369         88        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 3.5it/s 4.0s<2.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     29/100      3.26G      1.658      1.394       1.34         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.1s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 3.2it/s 8.3s<0.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.7s\n                   all        346       2909       0.45      0.382      0.356       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     30/100      3.26G      1.675      1.468      1.378        113        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 3.7it/s 4.4s<2.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     30/100      3.29G      1.651      1.433      1.356         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.6s0.7s\n                   all        346       2909      0.538      0.276      0.291      0.129\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     31/100      3.29G      1.601      1.366      1.328        106        640: 76% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ 16/21 3.9it/s 7.9s<1.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     31/100      3.31G       1.61      1.368      1.319         54        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.4s0.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 36% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4/11 3.5it/s 0.9s<2.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 82% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 9/11 2.1it/s 9.4s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.9s.4s\n                   all        346       2909      0.487      0.327       0.33      0.148\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     32/100      3.32G      1.666       1.43      1.331         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.8s0.8s\n                   all        346       2909      0.428      0.332      0.324      0.136\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     33/100      3.32G      1.625      1.457      1.373         87        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 3.7it/s 4.2s<2.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     33/100      3.33G      1.621      1.455      1.346         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.9s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.0it/s 5.8s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.4s.3s\n                   all        346       2909      0.486      0.323      0.324      0.139\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     34/100      3.36G        1.6      1.371      1.316         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.5s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 64% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 7/11 3.6it/s 1.7s<1.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.3s0.5s\n                   all        346       2909      0.503      0.349      0.354       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     35/100      3.38G      1.593      1.401      1.332         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.9s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.1it/s 5.9s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.4s.4s\n                   all        346       2909      0.431      0.363      0.339      0.144\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     36/100      3.38G       1.55      1.311      1.312        116        640: 90% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 19/21 3.8it/s 12.3s<0.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     36/100      3.39G      1.538      1.392      1.315          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.8s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 8.9s0.4s\n                   all        346       2909      0.477      0.349      0.354      0.158\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     37/100       3.4G      1.552      1.303      1.326         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.3s1.9s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.4it/s 5.7s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.6s.3s\n                   all        346       2909      0.497      0.272       0.27      0.113\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     38/100       3.4G      1.616      1.336      1.323         82        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 4.1it/s 4.5s<2.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     38/100      3.43G      1.616      1.351      1.323         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 64% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 7/11 4.3it/s 1.6s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.7s0.5s\n                   all        346       2909      0.544      0.299      0.316      0.133\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     39/100      3.45G      1.512      1.357      1.306         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.1s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.6it/s 6.2s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.7s.3s\n                   all        346       2909      0.495      0.298      0.298      0.126\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     40/100      3.45G      1.596      1.366      1.328        138        640: 62% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/21 3.9it/s 6.5s<2.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     40/100      3.46G      1.586       1.39      1.346         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.0s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.1s0.4s\n                   all        346       2909       0.51      0.369      0.346      0.146\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     41/100      3.46G      1.515       1.29      1.346         95        640: 10% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2/21 3.2it/s 0.5s<6.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     41/100      3.47G      1.524        1.3        1.3         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.9it/s 7.1s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2s/it 12.7s0.3s\n                   all        346       2909      0.485      0.303      0.325      0.138\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     42/100      3.47G      1.599      1.363      1.302         81        640: 5% ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1/21 1.9it/s 0.3s<10.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     42/100      3.49G      1.573      1.375      1.298         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.5s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 9.7s0.5s\n                   all        346       2909      0.514      0.306      0.328      0.138\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     43/100      3.49G      1.619      1.406       1.33        111        640: 86% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 18/21 1.7it/s 10.5s<1.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     43/100      3.51G        1.6      1.387      1.327         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.0s1.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.5it/s 5.9s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.4s.3s\n                   all        346       2909      0.431      0.362      0.339      0.143\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     44/100      3.53G      1.545      1.297      1.307         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.1s.5s\n                   all        346       2909      0.475      0.377      0.366      0.158\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     45/100      3.53G      1.528      1.279      1.298         79        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 2.6it/s 8.7s<1.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     45/100      3.54G      1.535      1.287      1.299         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.4s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 55% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 6/11 2.9it/s 2.9s<1.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.2it/s 6.7s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 12.1s.3s\n                   all        346       2909      0.438      0.305      0.298      0.121\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     46/100      3.56G      1.545      1.268      1.299         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 9.8s0.5s\n                   all        346       2909      0.555      0.261      0.278      0.117\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     47/100      3.56G      1.531      1.275      1.289        115        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 3.4it/s 9.4s<1.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     47/100      3.58G       1.54      1.257      1.294         18        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.1it/s 6.3s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.9s.3s\n                   all        346       2909       0.52      0.262      0.258      0.111\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     48/100      3.58G      1.529      1.221      1.286         77        640: 90% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 19/21 1.3it/s 12.5s<1.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     48/100       3.6G      1.524      1.212      1.281         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.0s0.4s\n                   all        346       2909      0.498      0.281      0.262      0.115\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     49/100       3.6G      1.515      1.233      1.288         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.1s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.1it/s 6.2s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.6s.3s\n                   all        346       2909      0.526      0.299      0.309      0.129\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     50/100       3.6G      1.509      1.282      1.279        171        640: 86% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 18/21 2.1it/s 10.4s<1.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     50/100      3.64G      1.506      1.286      1.283         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.2s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 64% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 7/11 3.8it/s 1.9s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.2s0.4s\n                   all        346       2909      0.523      0.274        0.3      0.132\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     51/100      3.65G      1.465      1.183      1.255         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 10.9s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.9it/s 7.1s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 12.6s0.4s\n                   all        346       2909      0.521      0.376      0.394      0.167\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     52/100      3.66G      1.486      1.161      1.272         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.4s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.5s0.5s\n                   all        346       2909      0.463      0.311      0.328       0.14\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     53/100      3.66G       1.54      1.232       1.26        148        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 3.6it/s 3.6s<2.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     53/100      3.67G       1.51      1.225      1.266         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.7it/s 5.6s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.2s.3s\n                   all        346       2909      0.536      0.289      0.297       0.12\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     54/100      3.67G      1.441       1.18      1.245        108        640: 48% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 10/21 2.7it/s 3.2s<4.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     54/100      3.67G      1.453      1.181      1.258         94        640: 86% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ 18/21 3.2it/s 11.5s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     54/100       3.7G      1.444      1.182       1.26         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.5s0.8s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.6s0.4s\n                   all        346       2909      0.469      0.352      0.346      0.154\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     55/100      3.72G      1.464      1.144      1.239         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.6s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.3it/s 5.4s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.3s.3s\n                   all        346       2909      0.512      0.326      0.339      0.153\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     56/100      3.73G      1.427      1.213      1.252         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.5s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.3s0.5s\n                   all        346       2909      0.549      0.262        0.3      0.141\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     57/100      3.73G      1.445       1.14      1.228        106        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/21 3.0it/s 2.9s<4.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     57/100      3.74G      1.428      1.128      1.231         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.7it/s 8.6s<0.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.9s\n                   all        346       2909      0.527      0.317      0.342       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     58/100      3.74G      1.413      1.114      1.232        122        640: 0% ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 0/21  0.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     58/100      3.77G       1.49        1.2      1.276         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 13.6s0.9s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.3s0.5s\n                   all        346       2909      0.557      0.285      0.314      0.131\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     59/100      3.79G      1.411      1.131       1.24         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 13.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.0it/s 5.1s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.8s.3s\n                   all        346       2909      0.523      0.319      0.332      0.144\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     60/100      3.79G      1.434      1.149      1.235        140        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/21 4.4it/s 2.7s<2.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     60/100       3.8G      1.434      1.137      1.231         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 14.1s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.4it/s 8.0s0.6s\n                   all        346       2909      0.543      0.302      0.328      0.144\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     61/100       3.8G      1.431      1.149      1.229         97        640: 62% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/21 4.0it/s 6.9s<2.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     61/100      3.81G      1.428      1.129      1.238         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.6it/s 8.8s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.0s\n                   all        346       2909      0.526      0.292      0.297      0.126\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     62/100      3.84G      1.425      1.134      1.252         26        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.3it/s 9.4s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.9s\n                   all        346       2909      0.498      0.318      0.322      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     63/100      3.84G      1.405      1.082      1.249         90        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 2.6it/s 4.4s<3.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     63/100      3.85G      1.406      1.107       1.24         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.4s\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.4it/s 8.4s<0.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.4s\n                   all        346       2909      0.543      0.301      0.333      0.141\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     64/100      3.87G      1.397      1.073      1.212         53        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 13.6s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 27% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/11 2.8it/s 0.7s<2.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.7it/s 8.0s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 9.9s\n                   all        346       2909      0.504      0.312      0.314      0.138\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     65/100      3.88G      1.431      1.126      1.232         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.5s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.5it/s 7.9s<0.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.7s\n                   all        346       2909      0.502      0.299      0.295      0.129\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     66/100      3.88G       1.42      1.104      1.217        111        640: 90% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 19/21 3.6it/s 12.9s<0.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     66/100      3.91G      1.429      1.137      1.212         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.9it/s 8.5s<0.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.4s\n                   all        346       2909      0.521      0.272      0.286      0.127\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     67/100      3.92G      1.362      1.208      1.224          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.6s0.9s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.4it/s 8.5s<0.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.5s\n                   all        346       2909      0.546      0.273      0.283      0.124\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     68/100      3.92G       1.39      1.075      1.212        157        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/21 5.0it/s 2.1s<2.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     68/100      3.94G      1.386      1.041      1.201         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.0s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.7it/s 8.2s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.0s\n                   all        346       2909      0.526      0.287      0.285      0.123\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     69/100      3.94G       1.43      1.078      1.212        122        640: 62% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/21 1.9it/s 5.8s<4.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     69/100      3.95G      1.402      1.053      1.212         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.3s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.2it/s 9.0s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.0s\n                   all        346       2909      0.553      0.283      0.303      0.133\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     70/100      3.95G      1.344      1.027      1.195         57        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 3.6it/s 10.8s<1.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     70/100      3.97G      1.359       1.03       1.19         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.2s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.8it/s 7.8s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 9.7s\n                   all        346       2909      0.526      0.308      0.311      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     71/100      3.97G      1.411      1.054      1.235         94        640: 71% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 15/21 1.8it/s 6.9s<3.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     71/100      3.99G      1.404      1.038      1.217         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.2it/s 10.0s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 11.0s\n                   all        346       2909       0.56      0.305      0.333      0.143\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     72/100      3.99G      1.415      1.059      1.224        102        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 2.5it/s 4.0s<4.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     72/100      4.01G      1.422      1.071      1.214         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.3it/s 9.5s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.1s\n                   all        346       2909      0.552       0.27      0.306      0.136\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     73/100      4.01G      1.387      1.078      1.189        165        640: 62% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 13/21 3.1it/s 5.4s<2.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     73/100      4.02G      1.373      1.069      1.205         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.8s1.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.2it/s 9.5s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.7s\n                   all        346       2909      0.566      0.259      0.287      0.125\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     74/100      4.04G      1.314     0.9666      1.179         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.1it/s 10.3s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 11.6s\n                   all        346       2909      0.558      0.292      0.322      0.138\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     75/100      4.04G      1.371     0.9984       1.17         79        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 2.4it/s 4.3s<4.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     75/100      4.06G      1.366          1      1.205         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.3it/s 9.0s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.1s\n                   all        346       2909      0.528      0.304      0.334       0.14\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     76/100      4.06G      1.403      1.014      1.195         95        640: 48% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 10/21 3.0it/s 3.4s<3.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     76/100      4.07G      1.358     0.9894      1.181         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.2s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.1it/s 9.7s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.3s\n                   all        346       2909      0.515      0.302      0.312      0.135\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     77/100      4.08G      1.274      0.979      1.165         19        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.7s0.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.9it/s 8.2s<0.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.1s\n                   all        346       2909      0.547      0.273      0.289      0.123\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     78/100      4.08G      1.281     0.9864      1.186        150        640: 52% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 11/21 3.6it/s 3.4s<2.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     78/100      4.11G        1.3      0.993      1.175         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.1it/s 10.1s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.1it/s 10.6s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.3s\n                   all        346       2909      0.551      0.276      0.292      0.128\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     79/100      4.13G      1.328     0.9739      1.184         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 13.6s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 27% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/11 2.7it/s 0.8s<3.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.7it/s 8.5s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.6s\n                   all        346       2909      0.568      0.281      0.314      0.138\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     80/100      4.14G       1.35      1.019      1.165         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.2s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 36% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4/11 2.9it/s 1.1s<2.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.3it/s 8.5s<0.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.0s\n                   all        346       2909      0.545      0.312      0.324      0.136\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     81/100      4.15G      1.354      1.006      1.186         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.3s0.7s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 55% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 6/11 4.2it/s 1.2s<1.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.8it/s 7.9s<0.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.2s\n                   all        346       2909      0.546       0.29      0.315      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     82/100      4.18G      1.314     0.9686      1.185         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.0s0.6s\n                   all        346       2909      0.598      0.265      0.297      0.131\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     83/100      4.18G      1.341     0.9674      1.161         92        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/21 3.6it/s 2.7s<3.3s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     83/100       4.2G      1.319     0.9444      1.168         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 13.8s0.8s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.6it/s 4.6s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.2s.3s\n                   all        346       2909      0.534      0.261      0.282      0.124\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     84/100      4.21G      1.296     0.9576       1.18         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.0s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.1s0.4s\n                   all        346       2909      0.533      0.273      0.294       0.13\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     85/100      4.21G       1.36      1.012      1.257         85        640: 10% ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2/21 3.1it/s 0.5s<6.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     85/100      4.22G       1.29     0.9315      1.186         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 55% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 6/11 3.1it/s 3.3s<1.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.1it/s 7.3s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 12.6s0.3s\n                   all        346       2909      0.568      0.265      0.296      0.132\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     86/100      4.25G      1.318     0.9543      1.184         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.4s0.4s\n                   all        346       2909      0.552      0.277      0.299      0.133\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     87/100      4.25G      1.261     0.9257      1.157         93        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 1.6it/s 8.8s<2.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     87/100      4.26G      1.247     0.9196      1.162         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.7s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.1it/s 7.1s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 12.5s0.3s\n                   all        346       2909      0.509      0.282      0.293      0.128\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     88/100      4.26G      1.224     0.9015      1.153        107        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 3.5it/s 8.8s<1.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     88/100      4.28G      1.219     0.9025       1.15         14        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.8it/s 11.6s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.5s0.4s\n                   all        346       2909      0.544      0.304      0.321       0.14\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     89/100      4.29G      1.269     0.9516      1.157         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.5s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 3.2it/s 7.1s<1.0s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 12.5s0.3s\n                   all        346       2909      0.568       0.28      0.308      0.135\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     90/100      4.29G      1.289     0.9255      1.136         59        640: 33% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 7/21 5.4it/s 1.4s<2.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     90/100      4.31G      1.275     0.9271      1.132         25        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.5s1.5s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.7s0.4s\n                   all        346       2909      0.591      0.266      0.298      0.129\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"Closing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     91/100      4.31G      1.236     0.8711      1.126         34        640: 14% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/21 1.7it/s 5.3s<10.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     91/100      4.33G      1.258     0.8893      1.146         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.0s/it 21.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 4.3it/s 1.7s<0.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.8it/s 5.7s<0.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.4it/s 8.1s\n                   all        346       2909      0.543      0.279        0.3      0.133\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     92/100      4.35G      1.228     0.9026      1.128          9        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 12.8s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.4it/s 9.0s<0.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.2it/s 9.3s\n                   all        346       2909      0.551      0.278        0.3      0.129\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     93/100      4.35G      1.175      0.837      1.126         62        640: 71% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 15/21 2.9it/s 8.2s<2.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     93/100      4.36G      1.207      0.849      1.138         13        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.2s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 27% ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3/11 2.8it/s 0.7s<2.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.0it/s 9.2s<0.5s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0s/it 11.2s\n                   all        346       2909       0.53      0.288      0.303      0.131\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     94/100      4.38G      1.175     0.8206      1.103         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.5it/s 14.0s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 64% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ 7/11 3.5it/s 1.8s<1.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.5it/s 8.3s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.7s\n                   all        346       2909      0.506      0.296      0.304      0.131\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     95/100       4.4G      1.198     0.8365      1.118          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.4s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.2it/s 8.6s<0.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.7s\n                   all        346       2909      0.515      0.294      0.304      0.132\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     96/100       4.4G      1.182     0.8157      1.111         76        640: 43% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 9/21 4.4it/s 2.1s<2.7s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     96/100      4.42G      1.158     0.7996       1.11         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.0it/s 10.7s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.1it/s 10.0s<0.9s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.7s\n                   all        346       2909      0.516      0.294      0.308      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     97/100      4.42G      1.158     0.7937      1.096         67        640: 33% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 7/21 5.3it/s 1.3s<2.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     97/100      4.43G      1.186     0.7989      1.121          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 2.1it/s 10.2s1.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.8it/s 10.3s<0.6s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1s/it 12.3s\n                   all        346       2909      0.526      0.294       0.31      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     98/100      4.43G      1.152      0.772      1.093         50        640: 81% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ 17/21 3.7it/s 8.8s<1.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     98/100      4.45G      1.135     0.8208      1.104          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.1s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 45% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 5/11 4.2it/s 1.0s<1.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 1.2it/s 9.6s<0.8s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.1it/s 10.5s\n                   all        346       2909      0.521      0.287      0.306      0.135\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     99/100      4.47G      1.155     0.7992      1.107          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.7it/s 12.3s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 91% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ 10/11 2.4it/s 8.6s<0.4s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.0it/s 10.5s\n                   all        346       2909      0.531      0.286      0.307      0.136\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K    100/100      4.47G      1.185     0.8063      1.129         91        640: 67% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ 14/21 3.1it/s 6.7s<2.2s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 61255 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K    100/100      4.49G      1.179     0.7971       1.12         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.6it/s 13.0s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.3it/s 8.7s0.7s\n                   all        346       2909      0.536      0.288      0.305      0.136\n","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\n100 epochs completed in 0.645 hours.\nOptimizer stripped from /kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final/weights/last.pt, 6.3MB\nOptimizer stripped from /kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final/weights/best.pt, 6.3MB\n\nValidating /kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final/weights/best.pt...\nUltralytics 8.3.240 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nModel summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 73% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ 8/11 2.6it/s 13.1s<1.1s","output_type":"stream"},{"name":"stderr","text":"Corrupt JPEG data: 67561 extraneous bytes before marker 0xd5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11/11 1.7s/it 18.7s0.4s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        346       2909      0.524      0.373      0.393      0.167\nSpeed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 1.5ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final\u001b[0m\n\n‚úÖ Pelatihan Selesai!\n\n--- Ringkasan Hasil Pelatihan ---\nMetrik Deteksi (Bounding Box - B):\n  mAP50 : 0.3931\n  mAP50-95 : 0.1666\nMenyimpan ke Excel: /kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final/Excel_Reports/yolo_production_YOLOv8_Final_Training_Model_final_training_results.xlsx\nMode: WRITE (File baru dibuat)\n‚úÖ Hasil pelatihan berhasil disimpan ke sheet 'Run_20251218_071138'\n\n--- Selesai ---\nModel: /kaggle/working/Hasil/yolo_production/YOLOv8_Final_Training_Model_final/weights/best.pt\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom ultralytics import YOLO\nimport datetime # Import untuk unique sheet names\n\n# --- KONFIGURASI PATH DAN HYPERPARAMETER ---\n\n# Path ke file data.yaml Anda\nDATA_YAML_PATH = \"/kaggle/working/data2.yaml\"\n\n# Ganti dengan hyperparameter terbaik hasil tuning manual Anda (atau gunakan default)\nBEST_LR = 0.005      # Learning Rate awal (Default)\nBEST_MOMENTUM = 0.937 # Momentum (Default)\nFINAL_EPOCHS = 20   # Jumlah epoch untuk pelatihan final (Ganti sesuai kebutuhan)\nBATCH_SIZE = 32        # Ukuran batch (Sesuaikan dengan VRAM GPU Kaggle)\n\n# Output directory di Google Drive untuk semua eksperimen YOLO\n# Ini akan membuat folder seperti: /content/drive/MyDrive/EAS VISIKOM/YOLO_Output/yolo_production/YOLOv8_Final_Training_Model2\nOUTPUT_BASE_DRIVE_DIR = \"/kaggle/working/Hasi3\"\n\n# Nama proyek (subfolder di OUTPUT_BASE_DRIVE_DIR)\nPROJECT_NAME = \"yolo_production\"\n\n# Nama eksperimen final (output akan disimpan di PROJECT_NAME/EXPERIMENT_NAME)\nEXPERIMENT_NAME = 'YOLOv8_Final_Training_Model4'\n\n# --- INIALISASI MODEL ---\n# Muat model pre-trained (yolov8n.pt)\nmodel = YOLO('yolov8n.pt')\n\n# ----------------------------------------------------\n# Bagian 1: Pelatihan Final\n# ----------------------------------------------------\nprint(\"---> Memulai Pelatihan Final YOLOv8 --->\")\n\n\nTRAINING_ARGS = {\n    'data': DATA_YAML_PATH,\n    'epochs': FINAL_EPOCHS,\n    'imgsz': 640,\n    'batch': BATCH_SIZE,\n    'name': EXPERIMENT_NAME, # Experiment name within the project\n    'project': os.path.join(OUTPUT_BASE_DRIVE_DIR, PROJECT_NAME), # Full path to the project folder on Drive\n    'lr0': BEST_LR,\n    'momentum': BEST_MOMENTUM,\n    'val': True, # Wajib untuk mendapatkan metrik validasi\n    'plots': True # Menghasilkan plot loss dan metrik\n}\n\n# Mulai Pelatihan\nresults = model.train(\n    **TRAINING_ARGS\n)\n\nprint(\"\\n‚úÖ Pelatihan Selesai!\")\n\n# ----------------------------------------------------\n# Bagian 2: Evaluasi dan Pencatatan Loss\n# ----------------------------------------------------\n\n# Tentukan path tempat hasil disimpan (otomatis dibuat oleh Ultralytics)\n# Ultralytics menyimpan hasil relatif terhadap direktori kerja saat ini,\n# biasanya di `runs/detect/project_name/experiment_name`.\n# Objek `results` secara langsung menyediakan direktori penyimpanan.\nOUTPUT_BASE_DIR = str(results.save_dir) # This will now be the Drive path\nBEST_MODEL_PATH = os.path.join(OUTPUT_BASE_DIR, 'weights', 'best.pt')\nRESULTS_CSV_PATH = os.path.join(OUTPUT_BASE_DIR, 'results.csv')\n\n# Path untuk menyimpan hasil ke file Excel\n# The Excel report should also go into the new OUTPUT_BASE_DIR\nEXCEL_OUTPUT_DIR = os.path.join(OUTPUT_BASE_DIR, 'Excel_Reports') # Changed this line\nos.makedirs(EXCEL_OUTPUT_DIR, exist_ok=True)\nEXCEL_REPORT_PATH = os.path.join(EXCEL_OUTPUT_DIR, f'{PROJECT_NAME}_{EXPERIMENT_NAME}_training_results.xlsx') # Added experiment name to differentiate reports\n\nprint(\"\\n--- Ringkasan Hasil Pelatihan ---\")\n\n# A. Mengambil Metrik mAP (Mean Average Precision)\ntry:\n    # Akses metrik langsung dari objek results.metrics (DetMetrics object)\n    map50 = results.metrics.box.map50\n    map50_95 = results.metrics.box.map\n\n    print(f\"Metrik Deteksi (Bounding Box - B):\")\n    print(f\"  mAP50 (Akurasi di IoU 50%): {map50:.4f}\")\n    print(f\"  mAP50-95 (Akurasi Rata-rata): {map50_95:.4f}\")\n\nexcept Exception as e:\n    print(f\"Terjadi error saat mencoba mengakses mAP dari results.metrics: {e}. Mencoba membaca dari CSV...\")\n    # Fallback to reading from CSV if direct access fails or for consistency\n    try:\n        df_results_full = pd.read_csv(RESULTS_CSV_PATH)\n        last_row_full = df_results_full.iloc[-1]\n        map50 = last_row_full['metrics/mAP50(B)']\n        map50_95 = last_row_full['metrics/mAP50-95(B)']\n        print(f\"Metrik Deteksi (Bounding Box - B) dari CSV:\")\n        print(f\"  mAP50 (Akurasi di IoU 50%): {map50:.4f}\")\n        print(f\"  mAP50-95 (Akurasi Rata-rata): {map50_95:.4f}\")\n    except Exception as csv_e:\n        print(f\"‚ùå ERROR membaca mAP dari CSV: {csv_e}\")\n\n# B. Mengambil Nilai Loss dari File results.csv dan menyimpannya ke Excel\ntry:\n    # Membaca file results.csv yang dibuat oleh Ultralytics\n    df_results = pd.read_csv(RESULTS_CSV_PATH)\n\n    # Mencari baris terakhir (epoch terakhir)\n    last_row = df_results.iloc[-1]\n\n    # Kolom Loss di Ultralytics:\n    # box_loss: Loss untuk bounding box localization\n    # cls_loss: Loss untuk classification\n    # dfl_loss: Loss untuk Distribution Focal Loss (digunakan di YOLOv8)\n\n    train_box_loss = last_row['train/box_loss']\n    train_cls_loss = last_row['train/cls_loss']\n    val_box_loss = last_row['val/box_loss']\n    val_cls_loss = last_row['val/cls_loss']\n\n    print(\"\\nNilai Loss di Akhir Pelatihan:\")\n    print(f\"  Total Train Loss (Box+Cls): {(train_box_loss + train_cls_loss):.4f}\")\n    print(f\"  Total Validasi Loss (Box+Cls): {(val_box_loss + val_cls_loss):.4f}\")\n    print(f\"  (Detail: Train Box Loss: {train_box_loss:.4f} | Val Box Loss: {val_box_loss:.4f})\")\n\n    # --- Menyimpan ke Excel/Spreadsheet --- #\n    # Buat nama sheet yang unik berdasarkan waktu\n    timestamp_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n    sheet_name = f\"Run_{timestamp_str}\"\n\n    # Gunakan pd.ExcelWriter untuk menulis ke file Excel.\n    # 'mode='a'' untuk append jika file sudah ada.\n    # 'if_sheet_exists='new'' akan membuat sheet baru jika nama sheet sudah ada (atau file belum ada).\n    # 'engine='openpyxl'' diperlukan untuk mode append dan .xlsx.\n    with pd.ExcelWriter(EXCEL_REPORT_PATH, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n        df_results.to_excel(writer, sheet_name=sheet_name, index=False)\n\n    print(f\"‚úÖ Hasil pelatihan disimpan ke sheet '{sheet_name}' di file Excel: {EXCEL_REPORT_PATH}\")\n\n\nexcept FileNotFoundError:\n    print(f\"\\n‚ùå ERROR: File results.csv tidak ditemukan di {RESULTS_CSV_PATH}.\")\n    print(\"Pastikan eksperimen berjalan sepenuhnya dan tidak ada error file system.\")\nexcept Exception as e:\n    print(f\"\\n‚ùå ERROR membaca Loss dari CSV atau menulis ke Excel: {e}\")\n\n# ----------------------------------------------------\n# Bagian 3: Konfirmasi Penyimpanan Model\n# ----------------------------------------------------\nprint(\"\\n--- Konfirmasi Penyimpanan Model ---\")\nprint(f\"Model terbaik tersimpan secara otomatis di:\")\nprint(f\"üíæ {BEST_MODEL_PATH}\")\nprint(f\"Log pelatihan (loss dan metrik) tersimpan di:\")\nprint(f\"üìÑ {RESULTS_CSV_PATH}\")\nprint(f\"Laporan Excel tersimpan di:\")\nprint(f\"üìä {EXCEL_REPORT_PATH}\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom ultralytics import YOLO\nimport datetime # Import untuk unique sheet names\n\n# --- KONFIGURASI PATH DAN HYPERPARAMETER ---\n\n# Path ke file data.yaml Anda\nDATA_YAML_PATH = \"/kaggle/working/data2.yaml\"\n\n# Ganti dengan hyperparameter terbaik hasil tuning manual Anda (atau gunakan default)\nBEST_LR = 0.005      # Learning Rate awal (Default)\nBEST_MOMENTUM = 0.937 # Momentum (Default)\nFINAL_EPOCHS = 20   # Jumlah epoch untuk pelatihan final (Ganti sesuai kebutuhan)\nBATCH_SIZE = 16        # Ukuran batch (Sesuaikan dengan VRAM GPU Kaggle)\n\n# Output directory di Google Drive untuk semua eksperimen YOLO\n# Ini akan membuat folder seperti: /content/drive/MyDrive/EAS VISIKOM/YOLO_Output/yolo_production/YOLOv8_Final_Training_Model2\nOUTPUT_BASE_DRIVE_DIR = \"/kaggle/working/Hasil\"\n\n# Nama proyek (subfolder di OUTPUT_BASE_DRIVE_DIR)\nPROJECT_NAME = \"yolo_production\"\n\n# Nama eksperimen final (output akan disimpan di PROJECT_NAME/EXPERIMENT_NAME)\nEXPERIMENT_NAME = 'YOLOv8_Final_Training_Model4'\n\n# --- INIALISASI MODEL ---\n# Muat model pre-trained (yolov8n.pt)\nmodel = YOLO('yolov8n.pt')\n\n# ----------------------------------------------------\n# Bagian 1: Pelatihan Final\n# ----------------------------------------------------\nprint(\"---> Memulai Pelatihan Final YOLOv8 --->\")\n\n\nTRAINING_ARGS = {\n    'data': DATA_YAML_PATH,\n    'epochs': FINAL_EPOCHS,\n    'imgsz': 640,\n    'batch': BATCH_SIZE,\n    'name': EXPERIMENT_NAME, # Experiment name within the project\n    'project': os.path.join(OUTPUT_BASE_DRIVE_DIR, PROJECT_NAME), # Full path to the project folder on Drive\n    'lr0': BEST_LR,\n    'momentum': BEST_MOMENTUM,\n    'val': True, # Wajib untuk mendapatkan metrik validasi\n    'plots': True # Menghasilkan plot loss dan metrik\n}\n\n# Mulai Pelatihan\nresults = model.train(\n    **TRAINING_ARGS\n)\n\nprint(\"\\n‚úÖ Pelatihan Selesai!\")\n\n# ----------------------------------------------------\n# Bagian 2: Evaluasi dan Pencatatan Loss\n# ----------------------------------------------------\n\n# Tentukan path tempat hasil disimpan (otomatis dibuat oleh Ultralytics)\n# Ultralytics menyimpan hasil relatif terhadap direktori kerja saat ini,\n# biasanya di `runs/detect/project_name/experiment_name`.\n# Objek `results` secara langsung menyediakan direktori penyimpanan.\nOUTPUT_BASE_DIR = str(results.save_dir) # This will now be the Drive path\nBEST_MODEL_PATH = os.path.join(OUTPUT_BASE_DIR, 'weights', 'best.pt')\nRESULTS_CSV_PATH = os.path.join(OUTPUT_BASE_DIR, 'results.csv')\n\n# Path untuk menyimpan hasil ke file Excel\n# The Excel report should also go into the new OUTPUT_BASE_DIR\nEXCEL_OUTPUT_DIR = os.path.join(OUTPUT_BASE_DIR, 'Excel_Reports') # Changed this line\nos.makedirs(EXCEL_OUTPUT_DIR, exist_ok=True)\nEXCEL_REPORT_PATH = os.path.join(EXCEL_OUTPUT_DIR, f'{PROJECT_NAME}_{EXPERIMENT_NAME}_training_results.xlsx') # Added experiment name to differentiate reports\n\nprint(\"\\n--- Ringkasan Hasil Pelatihan ---\")\n\n# A. Mengambil Metrik mAP (Mean Average Precision)\ntry:\n    # Akses metrik langsung dari objek results.metrics (DetMetrics object)\n    map50 = results.metrics.box.map50\n    map50_95 = results.metrics.box.map\n\n    print(f\"Metrik Deteksi (Bounding Box - B):\")\n    print(f\"  mAP50 (Akurasi di IoU 50%): {map50:.4f}\")\n    print(f\"  mAP50-95 (Akurasi Rata-rata): {map50_95:.4f}\")\n\nexcept Exception as e:\n    print(f\"Terjadi error saat mencoba mengakses mAP dari results.metrics: {e}. Mencoba membaca dari CSV...\")\n    # Fallback to reading from CSV if direct access fails or for consistency\n    try:\n        df_results_full = pd.read_csv(RESULTS_CSV_PATH)\n        last_row_full = df_results_full.iloc[-1]\n        map50 = last_row_full['metrics/mAP50(B)']\n        map50_95 = last_row_full['metrics/mAP50-95(B)']\n        print(f\"Metrik Deteksi (Bounding Box - B) dari CSV:\")\n        print(f\"  mAP50 (Akurasi di IoU 50%): {map50:.4f}\")\n        print(f\"  mAP50-95 (Akurasi Rata-rata): {map50_95:.4f}\")\n    except Exception as csv_e:\n        print(f\"‚ùå ERROR membaca mAP dari CSV: {csv_e}\")\n\n# B. Mengambil Nilai Loss dari File results.csv dan menyimpannya ke Excel\ntry:\n    # Membaca file results.csv yang dibuat oleh Ultralytics\n    df_results = pd.read_csv(RESULTS_CSV_PATH)\n\n    # Mencari baris terakhir (epoch terakhir)\n    last_row = df_results.iloc[-1]\n\n    # Kolom Loss di Ultralytics:\n    # box_loss: Loss untuk bounding box localization\n    # cls_loss: Loss untuk classification\n    # dfl_loss: Loss untuk Distribution Focal Loss (digunakan di YOLOv8)\n\n    train_box_loss = last_row['train/box_loss']\n    train_cls_loss = last_row['train/cls_loss']\n    val_box_loss = last_row['val/box_loss']\n    val_cls_loss = last_row['val/cls_loss']\n\n    print(\"\\nNilai Loss di Akhir Pelatihan:\")\n    print(f\"  Total Train Loss (Box+Cls): {(train_box_loss + train_cls_loss):.4f}\")\n    print(f\"  Total Validasi Loss (Box+Cls): {(val_box_loss + val_cls_loss):.4f}\")\n    print(f\"  (Detail: Train Box Loss: {train_box_loss:.4f} | Val Box Loss: {val_box_loss:.4f})\")\n\n    # --- Menyimpan ke Excel/Spreadsheet --- #\n    # Buat nama sheet yang unik berdasarkan waktu\n    timestamp_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n    sheet_name = f\"Run_{timestamp_str}\"\n\n    # Gunakan pd.ExcelWriter untuk menulis ke file Excel.\n    # 'mode='a'' untuk append jika file sudah ada.\n    # 'if_sheet_exists='new'' akan membuat sheet baru jika nama sheet sudah ada (atau file belum ada).\n    # 'engine='openpyxl'' diperlukan untuk mode append dan .xlsx.\n    with pd.ExcelWriter(EXCEL_REPORT_PATH, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n        df_results.to_excel(writer, sheet_name=sheet_name, index=False)\n\n    print(f\"‚úÖ Hasil pelatihan disimpan ke sheet '{sheet_name}' di file Excel: {EXCEL_REPORT_PATH}\")\n\n\nexcept FileNotFoundError:\n    print(f\"\\n‚ùå ERROR: File results.csv tidak ditemukan di {RESULTS_CSV_PATH}.\")\n    print(\"Pastikan eksperimen berjalan sepenuhnya dan tidak ada error file system.\")\nexcept Exception as e:\n    print(f\"\\n‚ùå ERROR membaca Loss dari CSV atau menulis ke Excel: {e}\")\n\n# ----------------------------------------------------\n# Bagian 3: Konfirmasi Penyimpanan Model\n# ----------------------------------------------------\nprint(\"\\n--- Konfirmasi Penyimpanan Model ---\")\nprint(f\"Model terbaik tersimpan secara otomatis di:\")\nprint(f\"üíæ {BEST_MODEL_PATH}\")\nprint(f\"Log pelatihan (loss dan metrik) tersimpan di:\")\nprint(f\"üìÑ {RESULTS_CSV_PATH}\")\nprint(f\"Laporan Excel tersimpan di:\")\nprint(f\"üìä {EXCEL_REPORT_PATH}\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ViTTT","metadata":{}},{"cell_type":"markdown","source":"Traing Model ViT, beberapa cell berisikan hyperparameter yang berbeda-beda. Lokasi penyimpanan hasil dapat disesuaikan kembali.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport pandas as pd\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# --- 1. KONFIGURASI DAN PATHS ---\nDATA_DIR = '/kaggle/input/crop-augmentation-citra-jagung/Data Crop_aug'\nOUTPUT_DIR = '/kaggle/working/HasilViT_Corn/p1'\nMODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, 'vision_transformer_corn_disease_best.pth')\nEXCEL_REPORT_PATH = os.path.join(OUTPUT_DIR, 'vit_training_evaluation_report.xlsx')\nCONF_MATRIX_PATH = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\nTRAINING_PLOT_PATH = os.path.join(OUTPUT_DIR, 'training_loss_accuracy_plot.png')\n\n# Hyperparameters\nBATCH_SIZE = 16\nNUM_EPOCHS = 10\nLEARNING_RATE = 1e-4\nVALIDATION_SPLIT = 0.2\n# Koreksi: Mengatur NUM_WORKERS ke 0 untuk stabilitas di lingkungan Notebook/Kaggle\nNUM_WORKERS = 0 \n\n# Otomatis hitung jumlah kelas\ntry:\n    NUM_CLASSES = len(os.listdir(DATA_DIR))\nexcept FileNotFoundError:\n    print(f\"ERROR: Data directory not found at {DATA_DIR}\")\n    NUM_CLASSES = 0 \n\n# Pastikan folder output ada\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"Semua output akan disimpan di: {OUTPUT_DIR}\")\n\n# --- 2. PREPROCESSING DAN AUGMENTASI KHUSUS VIT ---\n# Transformasi Gambar (Standar ViT/ImageNet)\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# --- 3. PEMBAGIAN DATA (TRAIN DAN VALIDATION) ---\n\nprint(\"--- Memuat dan Membagi Data ---\")\n\n# Memuat seluruh dataset dari folder\nfull_dataset = datasets.ImageFolder(DATA_DIR, data_transforms['val']) \nclass_names = full_dataset.classes\nprint(f\"Total Kelas: {class_names} ({NUM_CLASSES} kelas)\")\n\n# Tentukan ukuran data train dan validasi\nval_size = int(VALIDATION_SPLIT * len(full_dataset))\ntrain_size = len(full_dataset) - val_size\n\n# Pembagian acak\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# Terapkan transformasi yang benar secara manual\ntrain_dataset.dataset.transform = data_transforms['train']\nval_dataset.dataset.transform = data_transforms['val'] \n\n# Buat DataLoader\n# KOREKSI: Menggunakan NUM_WORKERS = 0 untuk menghindari masalah multiprocessing\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\ndataloaders = {'train': train_loader, 'val': val_loader}\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n\n# Tentukan Device (GPU jika tersedia)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Menggunakan perangkat: {device}\")\n\n# --- 4. INISIALISASI MODEL VIT ---\n# Fungsi untuk membuat model ViT (berguna saat loading model di Langkah 6)\ndef initialize_vit_model(num_classes):\n    model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n    # Mengganti Classification Head\n    num_ftrs = model.heads.head.in_features\n    model.heads.head = nn.Linear(num_ftrs, num_classes)\n    return model\n\nmodel = initialize_vit_model(NUM_CLASSES)\nprint(\"Vision Transformer (ViT-Base) berhasil dimuat.\")\n\nmodel = model.to(device)\n\n# Definisi Fungsi Loss dan Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# --- FUNGSI BARU UNTUK PLOTTING (SUDAH DIKOREKSI DARI NAMEERROR) ---\ndef plot_training_history(history, save_path):\n    \"\"\"Membuat plot Loss dan Accuracy dari histori training.\"\"\"\n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    plt.figure(figsize=(12, 5))\n\n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_loss'], label='Training Loss')\n    plt.plot(epochs, history['val_loss'], label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    val_acc_percent = [acc * 100 for acc in history['val_acc']] \n    plt.plot(epochs, val_acc_percent, label='Validation Accuracy', color='orange')\n    plt.title('Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(save_path)\n    print(f\"Plot Training History tersimpan di: {save_path}\") \n\n# --- 5. FUNGSI TRAINING DAN VALIDASI ---\n\ndef train_model(model, criterion, optimizer, num_epochs=NUM_EPOCHS):\n    start_time = time.time()\n    best_acc = 0.0\n\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []} \n\n    for epoch in range(num_epochs):\n        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  \n            else:\n                model.eval()   \n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_acc'].append(epoch_acc.item())\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n                print(f\"Model tersimpan di {MODEL_SAVE_PATH} (Acc: {best_acc:.4f})\")\n\n    time_elapsed = time.time() - start_time\n    print(f'\\nTraining Selesai dalam {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best Val Acc: {best_acc:.4f}')\n\n    return model, history\n\n# Lakukan Training\nmodel_ft, training_history = train_model(model, criterion, optimizer)\n\n# Visualisasikan History Training\nplot_training_history(training_history, TRAINING_PLOT_PATH)\n\n\n# --- 6. EVALUASI AKHIR, CONFUSION MATRIX, DAN PENYIMPANAN METRIK KE EXCEL ---\n\ndef evaluate_and_save_report(model_architecture, loader, class_names, history, conf_matrix_path, excel_report_path):\n    \n    # KOREKSI: Inisialisasi model di sini sebelum loading state_dict\n    model_eval = initialize_vit_model(len(class_names))\n    model_eval.load_state_dict(torch.load(MODEL_SAVE_PATH))\n    model_eval = model_eval.to(device)\n    model_eval.eval()\n\n    all_preds = []\n    all_labels = []\n\n    print(\"\\n--- Evaluasi Model Terbaik pada Data Validasi ---\")\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model_eval(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # --- A. Classification Report (Metrik) ---\n    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n    df_report = pd.DataFrame(report).transpose()\n    df_report.index.name = 'Metric'\n    print(\"\\nClassification Report (Data Validasi):\")\n    print(df_report)\n\n    # --- B. Confusion Matrix (Metrik Konvolusi) ---\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.savefig(conf_matrix_path)\n    print(f\"\\nConfusion Matrix tersimpan di: {conf_matrix_path}\")\n    \n    \n    # --- C. Simpan ke Excel ---\n    df_history = pd.DataFrame({\n        'Epoch': range(1, len(history['train_loss']) + 1),\n        'Train Loss': history['train_loss'],\n        'Val Loss': history['val_loss'],\n        'Train Accuracy': history['train_acc'], \n        'Val Accuracy': history['val_acc']\n    })\n\n    with pd.ExcelWriter(excel_report_path) as writer:\n        df_report.to_excel(writer, sheet_name='Evaluation_Metrics')\n        df_history.to_excel(writer, sheet_name='Training_History', index=False)\n\n    print(f\"\\nLaporan Evaluasi dan Histori Training tersimpan di: {excel_report_path}\")\n    print(\"Selesai. Semua output berada di folder:\", os.path.dirname(excel_report_path))\n\n# Lakukan Evaluasi dan Penyimpanan\n# Perhatikan bahwa kita menggunakan fungsi initialize_vit_model sebagai argumen placeholder\nevaluate_and_save_report(initialize_vit_model, \n                         val_loader, \n                         class_names, \n                         training_history, \n                         CONF_MATRIX_PATH, \n                         EXCEL_REPORT_PATH)","metadata":{"trusted":true,"_kg_hide-input":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport pandas as pd\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# --- 1. KONFIGURASI DAN PATHS ---\nDATA_DIR = '/kaggle/input/crop-augmentation-citra-jagung/Data Crop_aug'\nOUTPUT_DIR = '/kaggle/working/HasilViT_Corn/p2'\nMODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, 'vision_transformer_corn_disease_best.pth')\nEXCEL_REPORT_PATH = os.path.join(OUTPUT_DIR, 'vit_training_evaluation_report.xlsx')\nCONF_MATRIX_PATH = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\nTRAINING_PLOT_PATH = os.path.join(OUTPUT_DIR, 'training_loss_accuracy_plot.png')\n\n# Hyperparameters\nBATCH_SIZE = 32\nNUM_EPOCHS = 10\nLEARNING_RATE = 1e-4\nVALIDATION_SPLIT = 0.2\n# Koreksi: Mengatur NUM_WORKERS ke 0 untuk stabilitas di lingkungan Notebook/Kaggle\nNUM_WORKERS = 0 \n\n# Otomatis hitung jumlah kelas\ntry:\n    NUM_CLASSES = len(os.listdir(DATA_DIR))\nexcept FileNotFoundError:\n    print(f\"ERROR: Data directory not found at {DATA_DIR}\")\n    NUM_CLASSES = 0 \n\n# Pastikan folder output ada\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"Semua output akan disimpan di: {OUTPUT_DIR}\")\n\n# --- 2. PREPROCESSING DAN AUGMENTASI KHUSUS VIT ---\n# Transformasi Gambar (Standar ViT/ImageNet)\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# --- 3. PEMBAGIAN DATA (TRAIN DAN VALIDATION) ---\n\nprint(\"--- Memuat dan Membagi Data ---\")\n\n# Memuat seluruh dataset dari folder\nfull_dataset = datasets.ImageFolder(DATA_DIR, data_transforms['val']) \nclass_names = full_dataset.classes\nprint(f\"Total Kelas: {class_names} ({NUM_CLASSES} kelas)\")\n\n# Tentukan ukuran data train dan validasi\nval_size = int(VALIDATION_SPLIT * len(full_dataset))\ntrain_size = len(full_dataset) - val_size\n\n# Pembagian acak\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# Terapkan transformasi yang benar secara manual\ntrain_dataset.dataset.transform = data_transforms['train']\nval_dataset.dataset.transform = data_transforms['val'] \n\n# Buat DataLoader\n# KOREKSI: Menggunakan NUM_WORKERS = 0 untuk menghindari masalah multiprocessing\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\ndataloaders = {'train': train_loader, 'val': val_loader}\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n\n# Tentukan Device (GPU jika tersedia)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Menggunakan perangkat: {device}\")\n\n# --- 4. INISIALISASI MODEL VIT ---\n# Fungsi untuk membuat model ViT (berguna saat loading model di Langkah 6)\ndef initialize_vit_model(num_classes):\n    model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n    # Mengganti Classification Head\n    num_ftrs = model.heads.head.in_features\n    model.heads.head = nn.Linear(num_ftrs, num_classes)\n    return model\n\nmodel = initialize_vit_model(NUM_CLASSES)\nprint(\"Vision Transformer (ViT-Base) berhasil dimuat.\")\n\nmodel = model.to(device)\n\n# Definisi Fungsi Loss dan Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# --- FUNGSI BARU UNTUK PLOTTING (SUDAH DIKOREKSI DARI NAMEERROR) ---\ndef plot_training_history(history, save_path):\n    \"\"\"Membuat plot Loss dan Accuracy dari histori training.\"\"\"\n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    plt.figure(figsize=(12, 5))\n\n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_loss'], label='Training Loss')\n    plt.plot(epochs, history['val_loss'], label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    val_acc_percent = [acc * 100 for acc in history['val_acc']] \n    plt.plot(epochs, val_acc_percent, label='Validation Accuracy', color='orange')\n    plt.title('Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(save_path)\n    print(f\"Plot Training History tersimpan di: {save_path}\") \n\n# --- 5. FUNGSI TRAINING DAN VALIDASI ---\n\ndef train_model(model, criterion, optimizer, num_epochs=NUM_EPOCHS):\n    start_time = time.time()\n    best_acc = 0.0\n\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []} \n\n    for epoch in range(num_epochs):\n        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  \n            else:\n                model.eval()   \n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_acc'].append(epoch_acc.item())\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n                print(f\"Model tersimpan di {MODEL_SAVE_PATH} (Acc: {best_acc:.4f})\")\n\n    time_elapsed = time.time() - start_time\n    print(f'\\nTraining Selesai dalam {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best Val Acc: {best_acc:.4f}')\n\n    return model, history\n\n# Lakukan Training\nmodel_ft, training_history = train_model(model, criterion, optimizer)\n\n# Visualisasikan History Training\nplot_training_history(training_history, TRAINING_PLOT_PATH)\n\n\n# --- 6. EVALUASI AKHIR, CONFUSION MATRIX, DAN PENYIMPANAN METRIK KE EXCEL ---\n\ndef evaluate_and_save_report(model_architecture, loader, class_names, history, conf_matrix_path, excel_report_path):\n    \n    # KOREKSI: Inisialisasi model di sini sebelum loading state_dict\n    model_eval = initialize_vit_model(len(class_names))\n    model_eval.load_state_dict(torch.load(MODEL_SAVE_PATH))\n    model_eval = model_eval.to(device)\n    model_eval.eval()\n\n    all_preds = []\n    all_labels = []\n\n    print(\"\\n--- Evaluasi Model Terbaik pada Data Validasi ---\")\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model_eval(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # --- A. Classification Report (Metrik) ---\n    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n    df_report = pd.DataFrame(report).transpose()\n    df_report.index.name = 'Metric'\n    print(\"\\nClassification Report (Data Validasi):\")\n    print(df_report)\n\n    # --- B. Confusion Matrix (Metrik Konvolusi) ---\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.savefig(conf_matrix_path)\n    print(f\"\\nConfusion Matrix tersimpan di: {conf_matrix_path}\")\n    \n    \n    # --- C. Simpan ke Excel ---\n    df_history = pd.DataFrame({\n        'Epoch': range(1, len(history['train_loss']) + 1),\n        'Train Loss': history['train_loss'],\n        'Val Loss': history['val_loss'],\n        'Train Accuracy': history['train_acc'], \n        'Val Accuracy': history['val_acc']\n    })\n\n    with pd.ExcelWriter(excel_report_path) as writer:\n        df_report.to_excel(writer, sheet_name='Evaluation_Metrics')\n        df_history.to_excel(writer, sheet_name='Training_History', index=False)\n\n    print(f\"\\nLaporan Evaluasi dan Histori Training tersimpan di: {excel_report_path}\")\n    print(\"Selesai. Semua output berada di folder:\", os.path.dirname(excel_report_path))\n\n# Lakukan Evaluasi dan Penyimpanan\n# Perhatikan bahwa kita menggunakan fungsi initialize_vit_model sebagai argumen placeholder\nevaluate_and_save_report(initialize_vit_model, \n                         val_loader, \n                         class_names, \n                         training_history, \n                         CONF_MATRIX_PATH, \n                         EXCEL_REPORT_PATH)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport pandas as pd\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# --- 1. KONFIGURASI DAN PATHS ---\nDATA_DIR = '/kaggle/input/crop-augmentation-citra-jagung/Data Crop_aug'\nOUTPUT_DIR = '/kaggle/working/HasilViT_Corn/p3'\nMODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, 'vision_transformer_corn_disease_best.pth')\nEXCEL_REPORT_PATH = os.path.join(OUTPUT_DIR, 'vit_training_evaluation_report.xlsx')\nCONF_MATRIX_PATH = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\nTRAINING_PLOT_PATH = os.path.join(OUTPUT_DIR, 'training_loss_accuracy_plot.png')\n\n# Hyperparameters\nBATCH_SIZE = 16\nNUM_EPOCHS = 10\nLEARNING_RATE = 5e-5\nVALIDATION_SPLIT = 0.2\n# Koreksi: Mengatur NUM_WORKERS ke 0 untuk stabilitas di lingkungan Notebook/Kaggle\nNUM_WORKERS = 0 \n\n# Otomatis hitung jumlah kelas\ntry:\n    NUM_CLASSES = len(os.listdir(DATA_DIR))\nexcept FileNotFoundError:\n    print(f\"ERROR: Data directory not found at {DATA_DIR}\")\n    NUM_CLASSES = 0 \n\n# Pastikan folder output ada\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"Semua output akan disimpan di: {OUTPUT_DIR}\")\n\n# --- 2. PREPROCESSING DAN AUGMENTASI KHUSUS VIT ---\n# Transformasi Gambar (Standar ViT/ImageNet)\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# --- 3. PEMBAGIAN DATA (TRAIN DAN VALIDATION) ---\n\nprint(\"--- Memuat dan Membagi Data ---\")\n\n# Memuat seluruh dataset dari folder\nfull_dataset = datasets.ImageFolder(DATA_DIR, data_transforms['val']) \nclass_names = full_dataset.classes\nprint(f\"Total Kelas: {class_names} ({NUM_CLASSES} kelas)\")\n\n# Tentukan ukuran data train dan validasi\nval_size = int(VALIDATION_SPLIT * len(full_dataset))\ntrain_size = len(full_dataset) - val_size\n\n# Pembagian acak\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# Terapkan transformasi yang benar secara manual\ntrain_dataset.dataset.transform = data_transforms['train']\nval_dataset.dataset.transform = data_transforms['val'] \n\n# Buat DataLoader\n# KOREKSI: Menggunakan NUM_WORKERS = 0 untuk menghindari masalah multiprocessing\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\ndataloaders = {'train': train_loader, 'val': val_loader}\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n\n# Tentukan Device (GPU jika tersedia)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Menggunakan perangkat: {device}\")\n\n# --- 4. INISIALISASI MODEL VIT ---\n# Fungsi untuk membuat model ViT (berguna saat loading model di Langkah 6)\ndef initialize_vit_model(num_classes):\n    model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n    # Mengganti Classification Head\n    num_ftrs = model.heads.head.in_features\n    model.heads.head = nn.Linear(num_ftrs, num_classes)\n    return model\n\nmodel = initialize_vit_model(NUM_CLASSES)\nprint(\"Vision Transformer (ViT-Base) berhasil dimuat.\")\n\nmodel = model.to(device)\n\n# Definisi Fungsi Loss dan Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# --- FUNGSI BARU UNTUK PLOTTING (SUDAH DIKOREKSI DARI NAMEERROR) ---\ndef plot_training_history(history, save_path):\n    \"\"\"Membuat plot Loss dan Accuracy dari histori training.\"\"\"\n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    plt.figure(figsize=(12, 5))\n\n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_loss'], label='Training Loss')\n    plt.plot(epochs, history['val_loss'], label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    val_acc_percent = [acc * 100 for acc in history['val_acc']] \n    plt.plot(epochs, val_acc_percent, label='Validation Accuracy', color='orange')\n    plt.title('Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(save_path)\n    print(f\"Plot Training History tersimpan di: {save_path}\") \n\n# --- 5. FUNGSI TRAINING DAN VALIDASI ---\n\ndef train_model(model, criterion, optimizer, num_epochs=NUM_EPOCHS):\n    start_time = time.time()\n    best_acc = 0.0\n\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []} \n\n    for epoch in range(num_epochs):\n        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  \n            else:\n                model.eval()   \n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_acc'].append(epoch_acc.item())\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n                print(f\"Model tersimpan di {MODEL_SAVE_PATH} (Acc: {best_acc:.4f})\")\n\n    time_elapsed = time.time() - start_time\n    print(f'\\nTraining Selesai dalam {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best Val Acc: {best_acc:.4f}')\n\n    return model, history\n\n# Lakukan Training\nmodel_ft, training_history = train_model(model, criterion, optimizer)\n\n# Visualisasikan History Training\nplot_training_history(training_history, TRAINING_PLOT_PATH)\n\n\n# --- 6. EVALUASI AKHIR, CONFUSION MATRIX, DAN PENYIMPANAN METRIK KE EXCEL ---\n\ndef evaluate_and_save_report(model_architecture, loader, class_names, history, conf_matrix_path, excel_report_path):\n    \n    # KOREKSI: Inisialisasi model di sini sebelum loading state_dict\n    model_eval = initialize_vit_model(len(class_names))\n    model_eval.load_state_dict(torch.load(MODEL_SAVE_PATH))\n    model_eval = model_eval.to(device)\n    model_eval.eval()\n\n    all_preds = []\n    all_labels = []\n\n    print(\"\\n--- Evaluasi Model Terbaik pada Data Validasi ---\")\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model_eval(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # --- A. Classification Report (Metrik) ---\n    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n    df_report = pd.DataFrame(report).transpose()\n    df_report.index.name = 'Metric'\n    print(\"\\nClassification Report (Data Validasi):\")\n    print(df_report)\n\n    # --- B. Confusion Matrix (Metrik Konvolusi) ---\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.savefig(conf_matrix_path)\n    print(f\"\\nConfusion Matrix tersimpan di: {conf_matrix_path}\")\n    \n    \n    # --- C. Simpan ke Excel ---\n    df_history = pd.DataFrame({\n        'Epoch': range(1, len(history['train_loss']) + 1),\n        'Train Loss': history['train_loss'],\n        'Val Loss': history['val_loss'],\n        'Train Accuracy': history['train_acc'], \n        'Val Accuracy': history['val_acc']\n    })\n\n    with pd.ExcelWriter(excel_report_path) as writer:\n        df_report.to_excel(writer, sheet_name='Evaluation_Metrics')\n        df_history.to_excel(writer, sheet_name='Training_History', index=False)\n\n    print(f\"\\nLaporan Evaluasi dan Histori Training tersimpan di: {excel_report_path}\")\n    print(\"Selesai. Semua output berada di folder:\", os.path.dirname(excel_report_path))\n\n# Lakukan Evaluasi dan Penyimpanan\n# Perhatikan bahwa kita menggunakan fungsi initialize_vit_model sebagai argumen placeholder\nevaluate_and_save_report(initialize_vit_model, \n                         val_loader, \n                         class_names, \n                         training_history, \n                         CONF_MATRIX_PATH, \n                         EXCEL_REPORT_PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, random_split\nimport pandas as pd\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport os\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# --- 1. KONFIGURASI DAN PATHS ---\nDATA_DIR = '/kaggle/input/crop-augmentation-citra-jagung/Data Crop_aug'\nOUTPUT_DIR = '/kaggle/working/HasilViT_Corn/p4'\nMODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, 'vision_transformer_corn_disease_best.pth')\nEXCEL_REPORT_PATH = os.path.join(OUTPUT_DIR, 'vit_training_evaluation_report.xlsx')\nCONF_MATRIX_PATH = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\nTRAINING_PLOT_PATH = os.path.join(OUTPUT_DIR, 'training_loss_accuracy_plot.png')\n\n# Hyperparameters\nBATCH_SIZE = 32\nNUM_EPOCHS = 10\nLEARNING_RATE = 5e-5\nVALIDATION_SPLIT = 0.2\n# Koreksi: Mengatur NUM_WORKERS ke 0 untuk stabilitas di lingkungan Notebook/Kaggle\nNUM_WORKERS = 0 \n\n# Otomatis hitung jumlah kelas\ntry:\n    NUM_CLASSES = len(os.listdir(DATA_DIR))\nexcept FileNotFoundError:\n    print(f\"ERROR: Data directory not found at {DATA_DIR}\")\n    NUM_CLASSES = 0 \n\n# Pastikan folder output ada\nos.makedirs(OUTPUT_DIR, exist_ok=True)\nprint(f\"Semua output akan disimpan di: {OUTPUT_DIR}\")\n\n# --- 2. PREPROCESSING DAN AUGMENTASI KHUSUS VIT ---\n# Transformasi Gambar (Standar ViT/ImageNet)\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# --- 3. PEMBAGIAN DATA (TRAIN DAN VALIDATION) ---\n\nprint(\"--- Memuat dan Membagi Data ---\")\n\n# Memuat seluruh dataset dari folder\nfull_dataset = datasets.ImageFolder(DATA_DIR, data_transforms['val']) \nclass_names = full_dataset.classes\nprint(f\"Total Kelas: {class_names} ({NUM_CLASSES} kelas)\")\n\n# Tentukan ukuran data train dan validasi\nval_size = int(VALIDATION_SPLIT * len(full_dataset))\ntrain_size = len(full_dataset) - val_size\n\n# Pembagian acak\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# Terapkan transformasi yang benar secara manual\ntrain_dataset.dataset.transform = data_transforms['train']\nval_dataset.dataset.transform = data_transforms['val'] \n\n# Buat DataLoader\n# KOREKSI: Menggunakan NUM_WORKERS = 0 untuk menghindari masalah multiprocessing\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n\ndataloaders = {'train': train_loader, 'val': val_loader}\ndataset_sizes = {'train': len(train_dataset), 'val': len(val_dataset)}\n\n# Tentukan Device (GPU jika tersedia)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Menggunakan perangkat: {device}\")\n\n# --- 4. INISIALISASI MODEL VIT ---\n# Fungsi untuk membuat model ViT (berguna saat loading model di Langkah 6)\ndef initialize_vit_model(num_classes):\n    model = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n    # Mengganti Classification Head\n    num_ftrs = model.heads.head.in_features\n    model.heads.head = nn.Linear(num_ftrs, num_classes)\n    return model\n\nmodel = initialize_vit_model(NUM_CLASSES)\nprint(\"Vision Transformer (ViT-Base) berhasil dimuat.\")\n\nmodel = model.to(device)\n\n# Definisi Fungsi Loss dan Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# --- FUNGSI BARU UNTUK PLOTTING (SUDAH DIKOREKSI DARI NAMEERROR) ---\ndef plot_training_history(history, save_path):\n    \"\"\"Membuat plot Loss dan Accuracy dari histori training.\"\"\"\n    epochs = range(1, len(history['train_loss']) + 1)\n    \n    plt.figure(figsize=(12, 5))\n\n    # Plot Loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_loss'], label='Training Loss')\n    plt.plot(epochs, history['val_loss'], label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    # Plot Accuracy\n    plt.subplot(1, 2, 2)\n    val_acc_percent = [acc * 100 for acc in history['val_acc']] \n    plt.plot(epochs, val_acc_percent, label='Validation Accuracy', color='orange')\n    plt.title('Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig(save_path)\n    print(f\"Plot Training History tersimpan di: {save_path}\") \n\n# --- 5. FUNGSI TRAINING DAN VALIDASI ---\n\ndef train_model(model, criterion, optimizer, num_epochs=NUM_EPOCHS):\n    start_time = time.time()\n    best_acc = 0.0\n\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []} \n\n    for epoch in range(num_epochs):\n        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  \n            else:\n                model.eval()   \n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            history[f'{phase}_loss'].append(epoch_loss)\n            history[f'{phase}_acc'].append(epoch_acc.item())\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), MODEL_SAVE_PATH)\n                print(f\"Model tersimpan di {MODEL_SAVE_PATH} (Acc: {best_acc:.4f})\")\n\n    time_elapsed = time.time() - start_time\n    print(f'\\nTraining Selesai dalam {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best Val Acc: {best_acc:.4f}')\n\n    return model, history\n\n# Lakukan Training\nmodel_ft, training_history = train_model(model, criterion, optimizer)\n\n# Visualisasikan History Training\nplot_training_history(training_history, TRAINING_PLOT_PATH)\n\n\n# --- 6. EVALUASI AKHIR, CONFUSION MATRIX, DAN PENYIMPANAN METRIK KE EXCEL ---\n\ndef evaluate_and_save_report(model_architecture, loader, class_names, history, conf_matrix_path, excel_report_path):\n    \n    # KOREKSI: Inisialisasi model di sini sebelum loading state_dict\n    model_eval = initialize_vit_model(len(class_names))\n    model_eval.load_state_dict(torch.load(MODEL_SAVE_PATH))\n    model_eval = model_eval.to(device)\n    model_eval.eval()\n\n    all_preds = []\n    all_labels = []\n\n    print(\"\\n--- Evaluasi Model Terbaik pada Data Validasi ---\")\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model_eval(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # --- A. Classification Report (Metrik) ---\n    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n    df_report = pd.DataFrame(report).transpose()\n    df_report.index.name = 'Metric'\n    print(\"\\nClassification Report (Data Validasi):\")\n    print(df_report)\n\n    # --- B. Confusion Matrix (Metrik Konvolusi) ---\n    cm = confusion_matrix(all_labels, all_preds)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.savefig(conf_matrix_path)\n    print(f\"\\nConfusion Matrix tersimpan di: {conf_matrix_path}\")\n    \n    \n    # --- C. Simpan ke Excel ---\n    df_history = pd.DataFrame({\n        'Epoch': range(1, len(history['train_loss']) + 1),\n        'Train Loss': history['train_loss'],\n        'Val Loss': history['val_loss'],\n        'Train Accuracy': history['train_acc'], \n        'Val Accuracy': history['val_acc']\n    })\n\n    with pd.ExcelWriter(excel_report_path) as writer:\n        df_report.to_excel(writer, sheet_name='Evaluation_Metrics')\n        df_history.to_excel(writer, sheet_name='Training_History', index=False)\n\n    print(f\"\\nLaporan Evaluasi dan Histori Training tersimpan di: {excel_report_path}\")\n    print(\"Selesai. Semua output berada di folder:\", os.path.dirname(excel_report_path))\n\n# Lakukan Evaluasi dan Penyimpanan\n# Perhatikan bahwa kita menggunakan fungsi initialize_vit_model sebagai argumen placeholder\nevaluate_and_save_report(initialize_vit_model, \n                         val_loader, \n                         class_names, \n                         training_history, \n                         CONF_MATRIX_PATH, \n                         EXCEL_REPORT_PATH)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN","metadata":{}},{"cell_type":"markdown","source":"Traing Model CNN, beberapa cell berisikan hyperparameter yang berbeda-beda. Lokasi penyimpanan hasil dapat disesuaikan kembali.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.metrics import classification_report\n\n# 1. KONFIGURASI & PERSIAPAN FOLDER\nDATASET_PATH = '/kaggle/input/crop-augmentation-citra-jagung/Data Crop_aug' # Ganti dengan path dataset Anda\nOUTPUT_DIR = '/kaggle/working/HasilCNN2'   # Nama folder output\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nBATCH_SIZE = 64\nRANDOM_SEED = 123\n\n# Membuat folder output jika belum ada\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    print(f\"Folder '{OUTPUT_DIR}' berhasil dibuat.\")\n\n# 2. LOAD DATASET\n# Train Split (80%)\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=RANDOM_SEED,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE\n)\n\n# Val Split (20%) - Untuk Validasi saat Training\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=RANDOM_SEED,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE\n)\n\n# Simpan nama kelas\nclass_names = train_ds.class_names\nnum_classes = len(class_names)\n\n# Optimasi dataset untuk training\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n# 3. MEMBANGUN MODEL\nmodel = models.Sequential([\n    layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# 4. CALLBACK UNTUK MENYIMPAN MODEL TERBAIK\n# Model hanya akan disimpan jika 'val_accuracy' meningkat\ncheckpoint_path = os.path.join(OUTPUT_DIR, 'model_terbaik.keras')\nmodel_checkpoint = callbacks.ModelCheckpoint(\n    filepath=checkpoint_path,\n    save_best_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1\n)\n\n# 5. TRAINING\nEPOCHS = 10\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=[model_checkpoint] # Tambahkan callback di sini\n)\n\n# 6. SIMPAN PLOT GRAFIK KE FOLDER\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(EPOCHS)\n\nplt.figure(figsize=(12, 5))\n\n# Plot Akurasi\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\n# Plot Loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\n# Simpan gambar\nplot_path = os.path.join(OUTPUT_DIR, 'grafik_akurasi_loss.png')\nplt.savefig(plot_path)\nprint(f\"Grafik disimpan di: {plot_path}\")\nplt.close() # Tutup plot agar tidak memakan memori\n\n# 7. EVALUASI METRIK LENGKAP & SIMPAN KE EXCEL\nprint(\"Sedang menghitung metrik evaluasi...\")\n\n# Kita perlu meload ulang data validasi TANPA shuffle agar urutan prediksi sesuai label\nval_ds_eval = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=RANDOM_SEED,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    shuffle=False # PENTING: Jangan di-shuffle untuk evaluasi\n)\n\n# Ambil label asli (y_true) dan prediksi (y_pred)\ny_true = []\ny_pred = []\n\n# Loop batch untuk prediksi\nfor images, labels in val_ds_eval:\n    y_true.extend(labels.numpy())\n    predictions = model.predict(images, verbose=0)\n    y_pred.extend(np.argmax(predictions, axis=1))\n\n# Buat Report menggunakan Scikit-Learn\nreport_dict = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n\n# Konversi ke Pandas DataFrame\ndf_report = pd.DataFrame(report_dict).transpose()\n\n# Simpan ke Excel\nexcel_path = os.path.join(OUTPUT_DIR, 'laporan_evaluasi.xlsx')\ndf_report.to_excel(excel_path)\n\nprint(f\"File Excel evaluasi disimpan di: {excel_path}\")\nprint(\"Selesai.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, callbacks\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.metrics import classification_report\n\n# 1. KONFIGURASI & PERSIAPAN FOLDER\nDATASET_PATH = '/kaggle/input/crop-augmentation-citra-jagung/Data Crop_aug' # Ganti dengan path dataset Anda\nOUTPUT_DIR = '/kaggle/working/HasilCNN'   # Nama folder output\nIMG_HEIGHT = 128\nIMG_WIDTH = 128\nBATCH_SIZE = 32\nRANDOM_SEED = 123\n\n# Membuat folder output jika belum ada\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    print(f\"Folder '{OUTPUT_DIR}' berhasil dibuat.\")\n\n# 2. LOAD DATASET\n# Train Split (80%)\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=RANDOM_SEED,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE\n)\n\n# Val Split (20%) - Untuk Validasi saat Training\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=RANDOM_SEED,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE\n)\n\n# Simpan nama kelas\nclass_names = train_ds.class_names\nnum_classes = len(class_names)\n\n# Optimasi dataset untuk training\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n\n# 3. MEMBANGUN MODEL\nmodel = models.Sequential([\n    layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n    layers.Conv2D(32, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.MaxPooling2D((2, 2)),\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(num_classes, activation='softmax')\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# 4. CALLBACK UNTUK MENYIMPAN MODEL TERBAIK\n# Model hanya akan disimpan jika 'val_accuracy' meningkat\ncheckpoint_path = os.path.join(OUTPUT_DIR, 'model_terbaik.keras')\nmodel_checkpoint = callbacks.ModelCheckpoint(\n    filepath=checkpoint_path,\n    save_best_only=True,\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1\n)\n\n# 5. TRAINING\nEPOCHS = 10\nhistory = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    epochs=EPOCHS,\n    callbacks=[model_checkpoint] # Tambahkan callback di sini\n)\n\n# 6. SIMPAN PLOT GRAFIK KE FOLDER\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(EPOCHS)\n\nplt.figure(figsize=(12, 5))\n\n# Plot Akurasi\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\n# Plot Loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\n\n# Simpan gambar\nplot_path = os.path.join(OUTPUT_DIR, 'grafik_akurasi_loss.png')\nplt.savefig(plot_path)\nprint(f\"Grafik disimpan di: {plot_path}\")\nplt.close() # Tutup plot agar tidak memakan memori\n\n# 7. EVALUASI METRIK LENGKAP & SIMPAN KE EXCEL\nprint(\"Sedang menghitung metrik evaluasi...\")\n\n# Kita perlu meload ulang data validasi TANPA shuffle agar urutan prediksi sesuai label\nval_ds_eval = tf.keras.utils.image_dataset_from_directory(\n    DATASET_PATH,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=RANDOM_SEED,\n    image_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    shuffle=False # PENTING: Jangan di-shuffle untuk evaluasi\n)\n\n# Ambil label asli (y_true) dan prediksi (y_pred)\ny_true = []\ny_pred = []\n\n# Loop batch untuk prediksi\nfor images, labels in val_ds_eval:\n    y_true.extend(labels.numpy())\n    predictions = model.predict(images, verbose=0)\n    y_pred.extend(np.argmax(predictions, axis=1))\n\n# Buat Report menggunakan Scikit-Learn\nreport_dict = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n\n# Konversi ke Pandas DataFrame\ndf_report = pd.DataFrame(report_dict).transpose()\n\n# Simpan ke Excel\nexcel_path = os.path.join(OUTPUT_DIR, 'laporan_evaluasi.xlsx')\ndf_report.to_excel(excel_path)\n\nprint(f\"File Excel evaluasi disimpan di: {excel_path}\")\nprint(\"Selesai.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}